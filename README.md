# 游뚽 Border Wait Times Scraper

Este proyecto recopila y procesa los tiempos de espera en las principales garitas de Tijuana, Mexicali y Tecate, obteniendo informaci칩n cada 10 minutos mediante **GitHub Actions** desde Bordify y mostr치ndolos en un sitio web con **JavaScript**.

## 游늷 Descripci칩n

Este sistema cuenta con scrapers en **Python** que extraen los tiempos de espera de cada garita, detectan el estado del tr치fico mediante colores (rojo, amarillo, verde) y clasifican los cruces como **vehiculares o peatonales**. La informaci칩n se almacena en archivos JSON y se actualiza cada 10 minutos autom치ticamente.

Un script en **JavaScript** consume estos datos para mostrarlos din치micamente en un sitio web.

## 游 Funcionalidad

- Extrae datos cada **10 minutos** desde Bordify.
- Identifica **tiempos de espera** para diferentes tipos de carriles (**General, Sentri, ReadyLane**).
- Detecta el estado del tr치fico mediante **colores** (rojo, amarillo, verde).
- Clasifica cada cruce como **vehicular o peatonal**.
- Extrae el **icono** correspondiente (auto o peat칩n).
- Guarda los datos en archivos **JSON**.
- **Publica la informaci칩n en un sitio web din치mico usando JavaScript.**


## 游 Instalaci칩n y Configuraci칩n

1. **Clonar el repositorio:**
   ```sh
   git clone https://github.com/tu_usuario/border-wait-times.git
   cd border-wait-times
   ```

2. **Instalar dependencias:**
   ```sh
   pip install -r requirements.txt
   ```

3. **Ejecutar los scrapers manualmente:**
   ```sh
   python3 scraper-tijuana.py
   python3 scraper-mexicali.py
   python3 scraper-tecate.py
   ```

4. **Ejecutar el script en JavaScript localmente:**
   ```sh
   node scraper.js
   ```

5. **Ver los datos generados en JSON:**
   ```sh
   cat wait-times-tijuana.json
   ```

## 游둹 Ejemplo de Salida JSON

```json
{
    "Garita Otay Mesa": [
        {
            "tipo": "General",
            "tiempo": "2:24 horas",
            "l칤neas_abiertas": "2 l칤neas abiertas",
            "color": "red",
            "icono": "vehicular"
        },
        {
            "tipo": "Sentri",
            "tiempo": "18 minutos",
            "l칤neas_abiertas": "3 l칤neas abiertas",
            "color": "green",
            "icono": "vehicular"
        }
    ],
    "Ultima_actualizacion": "2025-03-20 14:43"
}
```

## 游깷 Funcionamiento del Script en JavaScript

El script `scraper.js` obtiene los datos desde los archivos JSON y los muestra en un sitio web. 
Si se usa con **Webflow**, se puede incrustar el archivo `webflow script.js`.

Ejemplo de ejecuci칩n manual:
```sh
node scraper.js
```

## 游댃 Automatizaci칩n con GitHub Actions

El script `scraper.yml` ejecuta los scrapers **cada 10 minutos** de forma autom치tica y actualiza los archivos JSON en el repositorio.

```yaml
on:
  schedule:
    - cron: '*/10 * * * *'  # Ejecuta cada 10 minutos
  workflow_dispatch: {}  # Permite ejecuci칩n manual
```

## 游댌 Tecnolog칤as Utilizadas

- **Python** 游냀
- **JavaScript (Node.js)** 游닇
- **Selenium** 游깷
- **Puppeteer** 游뱄
- **WebDriver Manager** 游뚱
- **YAML** 游닇
- **JSON** 游늵
- **GitHub Actions** 游댃

## 游 Mantenimiento y Errores

Si encuentras errores, verifica lo siguiente:
- **El sitio Bordify est치 activo** y su estructura HTML no ha cambiado.
- **El WebDriver est치 actualizado:**
  ```sh
  pip install -U webdriver-manager
  ```
- **Las dependencias est치n instaladas correctamente.**
- **Para el script en JavaScript, aseg칰rate de tener Node.js instalado:**
  ```sh
  node -v
  ```

## 游닐 Contacto

Si tienes preguntas o mejoras, cont치ctanos en [tu_email@example.com](mailto:tu_email@example.com).

游늷 **Desarrollado por:** _MadMath Agency_ 游

