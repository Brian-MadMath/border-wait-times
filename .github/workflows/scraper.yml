name: Ejecutar Scraper

on:
  schedule:
    - cron: '*/10 * * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  run_scraper:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ“¥ Clonar repositorio
        uses: actions/checkout@v4

      - name: ğŸ Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: ğŸ›  Instalar dependencias
        run: |
          sudo apt update
          sudo apt install -y wget unzip google-chrome-stable

      - name: ğŸ”§ Instalar ChromeDriver compatible
        run: |
          CHROME_MAJOR_VERSION=$(google-chrome --version | awk '{print $3}' | cut -d '.' -f 1)
          CHROMEDRIVER_VERSION=$(curl -sS "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_$CHROME_MAJOR_VERSION")
          wget -q -O chromedriver.zip "https://chromedriver.storage.googleapis.com/$CHROMEDRIVER_VERSION/chromedriver_linux64.zip"
          unzip chromedriver.zip
          sudo mv chromedriver /usr/local/bin/
          chromedriver --version

      - name: ğŸš€ Ejecutar scraper
        run: |
          pip install selenium
          python scraper.py

      - name: ğŸ’¾ Commit y push
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          git add wait-times.json
          git commit -m "ğŸ”„ ActualizaciÃ³n automÃ¡tica: $(date +'%Y-%m-%d %H:%M')" || echo "Sin cambios"
          git push
